{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n",
    "from openai import AzureOpenAI  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"ENDPOINT_URL\")  \n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\")  \n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize Azure OpenAI Service client with key-based authentication    \n",
    "client = AzureOpenAI(  \n",
    "    azure_endpoint=endpoint,  \n",
    "    api_key=subscription_key,  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#Prepare the chat prompt \n",
    "chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Tell me a Joke.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "] \n",
    "    \n",
    "# Include speech result if speech is enabled  \n",
    "messages = chat_prompt  \n",
    "    \n",
    "# Generate the completion  \n",
    "completion = client.chat.completions.create(  \n",
    "    model=deployment,\n",
    "    messages=messages,\n",
    "    max_tokens=80,  \n",
    "    temperature=0.7,  \n",
    "    top_p=0.95,  \n",
    "    frequency_penalty=0,  \n",
    "    presence_penalty=0,\n",
    "    stop=None,  \n",
    "    stream=False\n",
    ")\n",
    "\n",
    "#print(completion.to_json()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's one for you:\\n\\nWhy don't skeletons fight each other?  \\nBecause they don't have the guts! ðŸ˜„\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=completion.choices[0]\n",
    "res.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HI\\Documents\\test-openai\\projects\\mcqgen\\env\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://vijay-m6f1i5sd-eastus2.openai.azure.com/ to https://vijay-m6f1i5sd-eastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HI\\Documents\\test-openai\\projects\\mcqgen\\env\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HI\\Documents\\test-openai\\projects\\mcqgen\\env\\Lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://vijay-m6f1i5sd-eastus2.openai.azure.com/ to https://vijay-m6f1i5sd-eastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize Azure OpenAI LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base=endpoint,  # Replace with your Azure OpenAI endpoint\n",
    "    openai_api_version=\"2024-05-01-preview\",  # Replace with your API version\n",
    "    deployment_name=deployment,  # Replace with your deployment name\n",
    "    openai_api_key=subscription_key,  # Replace with your Azure OpenAI API key\n",
    "    openai_api_type=\"azure\",\n",
    "    model_name=\"gpt-4o\" ,  # Replace with your model name\n",
    "    temperature=0.3\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['number', 'response_json', 'subject', 'text', 'tone'], input_types={}, partial_variables={}, template='\\nText:{text}\\nYou are an expert MCQ maker. Given the above text, it is your job to create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \\nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make {number} MCQs\\n### RESPONSE_JSON\\n{response_json}\\n\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_generation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['number', 'response_json', 'subject', 'text', 'tone'], input_types={}, partial_variables={}, template='\\nText:{text}\\nYou are an expert MCQ maker. Given the above text, it is your job to create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \\nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make {number} MCQs\\n### RESPONSE_JSON\\n{response_json}\\n\\n'), llm=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023EFEF566D0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023EFEF52490>, model_name='gpt-4o', temperature=0.3, model_kwargs={}, openai_api_key='FMh5EMpFkTG1M6Tcj447lkS4zrrfHI8DDnGuRqp3tvX0G61gB8CDJQQJ99BAACHYHv6XJ3w3AAAAACOGbimh', openai_api_base='https://vijay-m6f1i5sd-eastus2.openai.azure.com/openai/deployments/gpt-4o', openai_proxy='', openai_api_version='2024-05-01-preview', openai_api_type='azure'), output_key='quiz', output_parser=StrOutputParser(), llm_kwargs={})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
